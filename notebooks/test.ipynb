{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ğŸ  Hometown - Analytics Case\n",
    "## Pipeline Principal - Dados de Aerogeradores SIGEL/ANEEL\n",
    "\n",
    "Este notebook implementa um pipeline completo e idempotente para:\n",
    "- **ExtraÃ§Ã£o** de dados da API SIGEL/ANEEL\n",
    "- **TransformaÃ§Ã£o** de JSON para Parquet otimizado\n",
    "- **ConsolidaÃ§Ã£o** em CSV final para Tableau\n",
    "\n",
    "### CaracterÃ­sticas do Pipeline:\n",
    "- âœ… **Idempotente**: NÃ£o reprocessa dados desnecessariamente\n",
    "- âœ… **Baseado em dados**: Usa `DATA_ATUALIZACAO` da prÃ³pria API\n",
    "- âœ… **Paralelo**: ThreadPool para performance\n",
    "- âœ… **Robusto**: Retry, validaÃ§Ãµes e logs detalhados\n",
    "- âœ… **Limpo**: Auto-limpeza de dados antigos"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## ğŸ“¦ 1. Setup e ConfiguraÃ§Ã£o Inicial\n",
    "\n",
    "ConfiguraÃ§Ã£o do ambiente, imports e validaÃ§Ã£o da conectividade com a API."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ğŸ”§ ConfiguraÃ§Ã£o do ambiente...\n",
      "ğŸ“ Projeto root: /home/victor-jose/Documents/projetos/hometown\n",
      "ğŸ“ Src path: /home/victor-jose/Documents/projetos/hometown/src\n",
      "âœ… Paths configurados!\n"
     ]
    }
   ],
   "source": [
    "# Imports bÃ¡sicos e configuraÃ§Ã£o de paths\n",
    "import sys\n",
    "import json\n",
    "from pathlib import Path\n",
    "import pandas as pd\n",
    "\n",
    "# Configurar path do projeto\n",
    "project_root = Path.cwd().parent\n",
    "src_path = project_root / \"src\"\n",
    "sys.path.insert(0, str(src_path))\n",
    "\n",
    "print(\"ğŸ”§ ConfiguraÃ§Ã£o do ambiente...\")\n",
    "print(f\"ğŸ“ Projeto root: {project_root}\")\n",
    "print(f\"ğŸ“ Src path: {src_path}\")\n",
    "print(\"âœ… Paths configurados!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ğŸ“š MÃ³dulos importados com sucesso!\n",
      "ğŸŒ API URL: https://sigel.aneel.gov.br/arcgis/rest/services/PORTAL/WFS/MapServer/0/query\n",
      "ğŸ“„ Tamanho da pÃ¡gina: 1000 registros\n",
      "âœ… Setup concluÃ­do!\n"
     ]
    }
   ],
   "source": [
    "# Imports dos mÃ³dulos do projeto\n",
    "from extraction.extractors import SigelExtractor\n",
    "from extraction.validators import validate_api_connection, validate_extraction_results\n",
    "from transformation.processors import DataProcessor\n",
    "from consolidation.consolidators import DataConsolidator\n",
    "from config.settings import SIGEL_CONFIG\n",
    "from utils.logger import setup_logger\n",
    "from utils.exceptions import APIConnectionError, ValidationError\n",
    "\n",
    "# Setup do logger principal\n",
    "logger = setup_logger(__name__, \"pipeline.log\")\n",
    "\n",
    "print(\"ğŸ“š MÃ³dulos importados com sucesso!\")\n",
    "print(f\"ğŸŒ API URL: {SIGEL_CONFIG['url']}\")\n",
    "print(f\"ğŸ“„ Tamanho da pÃ¡gina: {SIGEL_CONFIG['page_size']} registros\")\n",
    "print(\"âœ… Setup concluÃ­do!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ğŸ” ValidaÃ§Ã£o da Conectividade\n",
    "\n",
    "Testa a conexÃ£o com a API SIGEL/ANEEL antes de iniciar o pipeline."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ğŸŒ Testando conectividade com a API SIGEL/ANEEL...\n",
      "2025-06-01 17:50:35 - extraction.validators - INFO - API conectada com sucesso. Total de registros: 23522\n",
      "âœ… API conectada com sucesso!\n",
      "2025-06-01 17:50:35 - __main__ - INFO - ValidaÃ§Ã£o de conectividade concluÃ­da com sucesso\n"
     ]
    }
   ],
   "source": [
    "# Testar conectividade com a API\n",
    "try:\n",
    "    print(\"ğŸŒ Testando conectividade com a API SIGEL/ANEEL...\")\n",
    "    \n",
    "    api_url = SIGEL_CONFIG[\"url\"]\n",
    "    connection_ok = validate_api_connection(api_url)\n",
    "    \n",
    "    if connection_ok:\n",
    "        print(\"âœ… API conectada com sucesso!\")\n",
    "        logger.info(\"ValidaÃ§Ã£o de conectividade concluÃ­da com sucesso\")\n",
    "    else:\n",
    "        print(\"âŒ Falha na conexÃ£o com API\")\n",
    "        \n",
    "except (APIConnectionError, ValidationError) as e:\n",
    "    print(f\"âŒ Erro de validaÃ§Ã£o: {e}\")\n",
    "    logger.error(f\"Erro de validaÃ§Ã£o: {e}\")\n",
    "except Exception as e:\n",
    "    print(f\"âŒ Erro inesperado: {e}\")\n",
    "    logger.error(f\"Erro inesperado durante validaÃ§Ã£o: {e}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## ğŸ§¹ 2. Comandos de Limpeza e ManutenÃ§Ã£o\n",
    "\n",
    "FunÃ§Ãµes utilitÃ¡rias para gerenciar dados e fazer limpeza quando necessÃ¡rio."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ğŸ“Š STATUS ATUAL DOS DADOS:\n",
      "========================================\n",
      "ğŸ—‚ï¸ Arquivos JSON (raw): 0\n",
      "ğŸ“¦ Arquivos Parquet (processed): 0\n",
      "ğŸ“„ Arquivos CSV (output): 0\n",
      "ğŸ’¾ Tamanho total: 0.00 MB\n",
      "\n",
      "==================================================\n",
      "ğŸ”§ COMANDOS DISPONÃVEIS:\n",
      "â€¢ show_current_data_status() - Mostra status dos dados\n",
      "â€¢ cleanup_all_data() - Remove todos os dados\n",
      "==================================================\n"
     ]
    }
   ],
   "source": [
    "def show_current_data_status():\n",
    "    \"\"\"Exibe status atual dos dados no projeto\"\"\"\n",
    "    print(\"ğŸ“Š STATUS ATUAL DOS DADOS:\")\n",
    "    print(\"=\"*40)\n",
    "    \n",
    "    # Contar arquivos em cada etapa\n",
    "    raw_files = list(Path(\"data/raw\").glob(\"aerogeradores_raw_*.json\")) if Path(\"data/raw\").exists() else []\n",
    "    processed_files = list(Path(\"data/processed\").glob(\"aerogeradores_processed_*.parquet\")) if Path(\"data/processed\").exists() else []\n",
    "    output_files = list(Path(\"data/output\").glob(\"aerogeradores_consolidado_*.csv\")) if Path(\"data/output\").exists() else []\n",
    "    \n",
    "    print(f\"ğŸ—‚ï¸ Arquivos JSON (raw): {len(raw_files)}\")\n",
    "    print(f\"ğŸ“¦ Arquivos Parquet (processed): {len(processed_files)}\")\n",
    "    print(f\"ğŸ“„ Arquivos CSV (output): {len(output_files)}\")\n",
    "    \n",
    "    # Calcular tamanhos\n",
    "    total_size = 0\n",
    "    for files, label in [(raw_files, \"JSONs\"), (processed_files, \"Parquets\"), (output_files, \"CSVs\")]:\n",
    "        if files:\n",
    "            size = sum(f.stat().st_size for f in files) / 1024 / 1024\n",
    "            total_size += size\n",
    "            print(f\"ğŸ’¾ Tamanho {label}: {size:.2f} MB\")\n",
    "    \n",
    "    print(f\"ğŸ’¾ Tamanho total: {total_size:.2f} MB\")\n",
    "    \n",
    "    return {\n",
    "        'raw_count': len(raw_files),\n",
    "        'processed_count': len(processed_files),\n",
    "        'output_count': len(output_files),\n",
    "        'total_size_mb': total_size\n",
    "    }\n",
    "\n",
    "def cleanup_all_data():\n",
    "    \"\"\"Remove todos os dados para recomeÃ§ar do zero\"\"\"\n",
    "    print(\"ğŸ§¹ INICIANDO LIMPEZA COMPLETA...\")\n",
    "    \n",
    "    # Instanciar classes para usar mÃ©todos de limpeza\n",
    "    extractor = SigelExtractor()\n",
    "    processor = DataProcessor()\n",
    "    consolidator = DataConsolidator()\n",
    "    \n",
    "    # Executar limpeza de cada etapa\n",
    "    raw_removed = extractor.cleanup_all_raw_data()\n",
    "    processed_removed = processor.cleanup_all_processed_data()\n",
    "    output_removed = consolidator.cleanup_all_output_data()\n",
    "    \n",
    "    total_removed = raw_removed + processed_removed + output_removed\n",
    "    \n",
    "    print(f\"ğŸ“Š RESUMO DA LIMPEZA:\")\n",
    "    print(f\"  ğŸ—‚ï¸ JSONs removidos: {raw_removed}\")\n",
    "    print(f\"  ğŸ“¦ Parquets removidos: {processed_removed}\")\n",
    "    print(f\"  ğŸ“„ CSVs removidos: {output_removed}\")\n",
    "    print(f\"  ğŸ—‘ï¸ Total de arquivos: {total_removed}\")\n",
    "    print(f\"âœ… Limpeza completa concluÃ­da!\")\n",
    "    \n",
    "    return total_removed\n",
    "\n",
    "# Mostrar status inicial\n",
    "status = show_current_data_status()\n",
    "\n",
    "print(\"\\n\" + \"=\"*50)\n",
    "print(\"ğŸ”§ COMANDOS DISPONÃVEIS:\")\n",
    "print(\"â€¢ show_current_data_status() - Mostra status dos dados\")\n",
    "print(\"â€¢ cleanup_all_data() - Remove todos os dados\")\n",
    "print(\"=\"*50)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## ğŸš€ 3. Pipeline Principal - ExtraÃ§Ã£o de Dados\n",
    "\n",
    "ExtraÃ§Ã£o idempotente de dados da API SIGEL/ANEEL. O sistema verifica automaticamente se os dados mudaram na API antes de fazer nova extraÃ§Ã£o."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ğŸ” VERIFICANDO FRESHNESS DOS DADOS...\n",
      "==================================================\n",
      "2025-06-01 17:50:35 - extraction.extractors - INFO - Verificando freshness dos dados...\n",
      "2025-06-01 17:50:37 - extraction.extractors - INFO - API Ãºltima atualizaÃ§Ã£o: 1673359590000\n",
      "2025-06-01 17:50:37 - extraction.extractors - INFO - Nossa Ãºltima extraÃ§Ã£o: 0\n",
      "2025-06-01 17:50:37 - extraction.extractors - INFO - Precisa atualizar: True\n",
      "ğŸ“Š STATUS DOS DADOS:\n",
      "  ğŸŒ API Ãºltima atualizaÃ§Ã£o: 1673359590000\n",
      "  ğŸ’¾ Nossa Ãºltima extraÃ§Ã£o: 0\n",
      "  ğŸ”„ Precisa atualizar: True\n",
      "  ğŸ“… Primeira execuÃ§Ã£o - nenhuma extraÃ§Ã£o anterior\n",
      "\n",
      "==================================================\n"
     ]
    }
   ],
   "source": [
    "# Instanciar extrator e verificar freshness dos dados\n",
    "print(\"ğŸ” VERIFICANDO FRESHNESS DOS DADOS...\")\n",
    "print(\"=\"*50)\n",
    "\n",
    "extractor = SigelExtractor()\n",
    "freshness = extractor.check_data_freshness()\n",
    "\n",
    "print(f\"ğŸ“Š STATUS DOS DADOS:\")\n",
    "print(f\"  ğŸŒ API Ãºltima atualizaÃ§Ã£o: {freshness['api_latest_update']}\")\n",
    "print(f\"  ğŸ’¾ Nossa Ãºltima extraÃ§Ã£o: {freshness['our_last_extraction']}\")\n",
    "print(f\"  ğŸ”„ Precisa atualizar: {freshness['needs_refresh']}\")\n",
    "\n",
    "if freshness['last_extraction_time']:\n",
    "    print(f\"  ğŸ“… Ãšltima extraÃ§Ã£o em: {freshness['last_extraction_time']}\")\n",
    "    print(f\"  ğŸ“Š Registros da Ãºltima extraÃ§Ã£o: {freshness['last_total_records']:,}\")\n",
    "else:\n",
    "    print(f\"  ğŸ“… Primeira execuÃ§Ã£o - nenhuma extraÃ§Ã£o anterior\")\n",
    "\n",
    "print(\"\\n\" + \"=\"*50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ğŸš€ EXECUTANDO EXTRAÃ‡ÃƒO DE DADOS...\n",
      "(O sistema decide automaticamente se precisa extrair baseado na DATA_ATUALIZACAO da API)\n",
      "\n",
      "2025-06-01 17:50:37 - extraction.extractors - INFO - Verificando freshness dos dados...\n",
      "2025-06-01 17:50:37 - extraction.extractors - INFO - API Ãºltima atualizaÃ§Ã£o: 1673359590000\n",
      "2025-06-01 17:50:37 - extraction.extractors - INFO - Nossa Ãºltima extraÃ§Ã£o: 0\n",
      "2025-06-01 17:50:37 - extraction.extractors - INFO - Precisa atualizar: True\n",
      "2025-06-01 17:50:37 - extraction.extractors - INFO - ğŸ”„ Dados da API foram atualizados, executando nova extraÃ§Ã£o...\n",
      "2025-06-01 17:50:39 - extraction.extractors - INFO - ğŸ“Š Total de registros: 23522\n",
      "2025-06-01 17:50:39 - extraction.extractors - INFO - ğŸ“„ Total de pÃ¡ginas: 24\n",
      "2025-06-01 17:50:39 - extraction.extractors - INFO - ğŸ“… Data de atualizaÃ§Ã£o da API: 1673359590000\n",
      "2025-06-01 17:50:39 - extraction.extractors - INFO - Extraindo pÃ¡gina 1/24\n",
      "2025-06-01 17:50:41 - extraction.extractors - INFO - Extraindo pÃ¡gina 2/24\n",
      "2025-06-01 17:50:43 - extraction.extractors - INFO - Extraindo pÃ¡gina 3/24\n",
      "2025-06-01 17:50:44 - extraction.extractors - INFO - Extraindo pÃ¡gina 4/24\n",
      "2025-06-01 17:50:45 - extraction.extractors - INFO - Extraindo pÃ¡gina 5/24\n",
      "2025-06-01 17:50:48 - extraction.extractors - INFO - Extraindo pÃ¡gina 6/24\n",
      "2025-06-01 17:50:48 - extraction.extractors - INFO - Extraindo pÃ¡gina 7/24\n",
      "2025-06-01 17:50:50 - extraction.extractors - INFO - Extraindo pÃ¡gina 8/24\n",
      "2025-06-01 17:50:54 - extraction.extractors - INFO - Extraindo pÃ¡gina 9/24\n",
      "2025-06-01 17:50:55 - extraction.extractors - INFO - Extraindo pÃ¡gina 10/24\n",
      "2025-06-01 17:50:57 - extraction.extractors - INFO - Extraindo pÃ¡gina 11/24\n",
      "2025-06-01 17:50:57 - extraction.extractors - INFO - Extraindo pÃ¡gina 12/24\n",
      "2025-06-01 17:50:58 - extraction.extractors - INFO - Extraindo pÃ¡gina 13/24\n",
      "2025-06-01 17:50:59 - extraction.extractors - INFO - Extraindo pÃ¡gina 14/24\n",
      "2025-06-01 17:51:00 - extraction.extractors - INFO - Extraindo pÃ¡gina 15/24\n",
      "2025-06-01 17:51:02 - extraction.extractors - INFO - Extraindo pÃ¡gina 16/24\n",
      "2025-06-01 17:51:04 - extraction.extractors - INFO - Extraindo pÃ¡gina 17/24\n",
      "2025-06-01 17:51:07 - extraction.extractors - INFO - Extraindo pÃ¡gina 18/24\n",
      "2025-06-01 17:51:09 - extraction.extractors - INFO - Extraindo pÃ¡gina 19/24\n",
      "2025-06-01 17:51:11 - extraction.extractors - INFO - Extraindo pÃ¡gina 20/24\n",
      "2025-06-01 17:51:12 - extraction.extractors - INFO - Extraindo pÃ¡gina 21/24\n",
      "2025-06-01 17:51:14 - extraction.extractors - INFO - Extraindo pÃ¡gina 22/24\n",
      "2025-06-01 17:51:15 - extraction.extractors - INFO - Extraindo pÃ¡gina 23/24\n",
      "2025-06-01 17:51:20 - extraction.extractors - INFO - Extraindo pÃ¡gina 24/24\n",
      "2025-06-01 17:51:23 - extraction.extractors - INFO - PÃ¡gina 3 salva: 1000 registros\n",
      "2025-06-01 17:51:23 - extraction.extractors - INFO - PÃ¡gina 11 salva: 1000 registros\n",
      "2025-06-01 17:51:23 - extraction.extractors - INFO - PÃ¡gina 5 salva: 1000 registros\n",
      "2025-06-01 17:51:23 - extraction.extractors - INFO - PÃ¡gina 8 salva: 1000 registros\n",
      "2025-06-01 17:51:23 - extraction.extractors - INFO - PÃ¡gina 15 salva: 1000 registros\n",
      "2025-06-01 17:51:23 - extraction.extractors - INFO - PÃ¡gina 1 salva: 1000 registros\n",
      "2025-06-01 17:51:23 - extraction.extractors - INFO - PÃ¡gina 6 salva: 1000 registros\n",
      "2025-06-01 17:51:23 - extraction.extractors - INFO - PÃ¡gina 18 salva: 1000 registros\n",
      "2025-06-01 17:51:23 - extraction.extractors - INFO - PÃ¡gina 23 salva: 1000 registros\n",
      "2025-06-01 17:51:23 - extraction.extractors - INFO - PÃ¡gina 17 salva: 1000 registros\n",
      "2025-06-01 17:51:23 - extraction.extractors - INFO - PÃ¡gina 4 salva: 1000 registros\n",
      "2025-06-01 17:51:23 - extraction.extractors - INFO - PÃ¡gina 19 salva: 1000 registros\n",
      "2025-06-01 17:51:23 - extraction.extractors - INFO - PÃ¡gina 2 salva: 1000 registros\n",
      "2025-06-01 17:51:23 - extraction.extractors - INFO - PÃ¡gina 16 salva: 1000 registros\n",
      "2025-06-01 17:51:23 - extraction.extractors - INFO - PÃ¡gina 20 salva: 1000 registros\n",
      "2025-06-01 17:51:23 - extraction.extractors - INFO - PÃ¡gina 9 salva: 1000 registros\n",
      "2025-06-01 17:51:23 - extraction.extractors - INFO - PÃ¡gina 7 salva: 1000 registros\n",
      "2025-06-01 17:51:23 - extraction.extractors - INFO - PÃ¡gina 21 salva: 1000 registros\n",
      "2025-06-01 17:51:23 - extraction.extractors - INFO - PÃ¡gina 10 salva: 1000 registros\n",
      "2025-06-01 17:51:23 - extraction.extractors - INFO - PÃ¡gina 13 salva: 1000 registros\n",
      "2025-06-01 17:51:23 - extraction.extractors - INFO - PÃ¡gina 12 salva: 1000 registros\n",
      "2025-06-01 17:51:23 - extraction.extractors - INFO - PÃ¡gina 22 salva: 1000 registros\n",
      "2025-06-01 17:51:23 - extraction.extractors - INFO - PÃ¡gina 14 salva: 1000 registros\n",
      "2025-06-01 17:51:23 - extraction.extractors - INFO - PÃ¡gina 24 salva: 522 registros\n",
      "2025-06-01 17:51:23 - extraction.extractors - INFO - Metadata salvo: Ãºltima atualizaÃ§Ã£o 1673359590000\n",
      "2025-06-01 17:51:23 - extraction.extractors - INFO - âœ… ExtraÃ§Ã£o concluÃ­da!\n",
      "2025-06-01 17:51:23 - extraction.extractors - INFO - ğŸ“ Arquivos salvos: 24\n",
      "2025-06-01 17:51:23 - extraction.extractors - INFO - ğŸ“Š Registros processados: 23522/23522\n",
      "\n",
      "ğŸ“Š RESULTADO DA EXTRAÃ‡ÃƒO:\n",
      "âœ… Arquivos JSON salvos: 24\n",
      "\n",
      "ğŸ“‹ Arquivos salvos (primeiros 3):\n",
      "  1. aerogeradores_raw_20250601_175037_page_0003.json (731.4 KB)\n",
      "  2. aerogeradores_raw_20250601_175037_page_0011.json (749.3 KB)\n",
      "  3. aerogeradores_raw_20250601_175037_page_0005.json (733.2 KB)\n",
      "  ... e mais 21 arquivos\n",
      "\n",
      "ğŸ’¾ Tamanho total: 16.94 MB\n",
      "ğŸ“ LocalizaÃ§Ã£o: data/raw/\n",
      "2025-06-01 17:51:23 - __main__ - INFO - ExtraÃ§Ã£o concluÃ­da: 24 arquivos\n"
     ]
    }
   ],
   "source": [
    "# Executar extraÃ§Ã£o (idempotente - sÃ³ extrai se necessÃ¡rio)\n",
    "print(\"ğŸš€ EXECUTANDO EXTRAÃ‡ÃƒO DE DADOS...\")\n",
    "print(\"(O sistema decide automaticamente se precisa extrair baseado na DATA_ATUALIZACAO da API)\\n\")\n",
    "\n",
    "try:\n",
    "    # ExtraÃ§Ã£o idempotente (force_refresh=False por padrÃ£o)\n",
    "    saved_files = extractor.extract_all_data()\n",
    "    \n",
    "    print(f\"\\nğŸ“Š RESULTADO DA EXTRAÃ‡ÃƒO:\")\n",
    "    print(f\"âœ… Arquivos JSON salvos: {len(saved_files)}\")\n",
    "    \n",
    "    if saved_files:\n",
    "        # Mostrar alguns arquivos como exemplo\n",
    "        print(f\"\\nğŸ“‹ Arquivos salvos (primeiros 3):\")\n",
    "        for i, file_path in enumerate(saved_files[:3]):\n",
    "            filename = Path(file_path).name\n",
    "            size = Path(file_path).stat().st_size / 1024  # KB\n",
    "            print(f\"  {i+1}. {filename} ({size:.1f} KB)\")\n",
    "        \n",
    "        if len(saved_files) > 3:\n",
    "            print(f\"  ... e mais {len(saved_files) - 3} arquivos\")\n",
    "        \n",
    "        # Calcular tamanho total\n",
    "        total_size = sum(Path(f).stat().st_size for f in saved_files) / 1024 / 1024\n",
    "        print(f\"\\nğŸ’¾ Tamanho total: {total_size:.2f} MB\")\n",
    "        print(f\"ğŸ“ LocalizaÃ§Ã£o: data/raw/\")\n",
    "    \n",
    "    logger.info(f\"ExtraÃ§Ã£o concluÃ­da: {len(saved_files)} arquivos\")\n",
    "    \n",
    "except Exception as e:\n",
    "    print(f\"âŒ Erro durante extraÃ§Ã£o: {e}\")\n",
    "    logger.error(f\"Erro durante extraÃ§Ã£o: {e}\")\n",
    "    raise"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ğŸ” VALIDANDO DADOS EXTRAÃDOS...\n",
      "2025-06-01 17:51:23 - extraction.validators - INFO - ValidaÃ§Ã£o da extraÃ§Ã£o concluÃ­da. 24 arquivos salvos\n",
      "âœ… ValidaÃ§Ã£o dos dados extraÃ­dos concluÃ­da!\n",
      "\n",
      "ğŸ” EXPLORANDO ESTRUTURA DOS DADOS:\n",
      "ğŸ“ Arquivo exemplo: aerogeradores_raw_20250601_175037_page_0003.json\n",
      "ğŸ“‹ Chaves principais: ['displayFieldName', 'fieldAliases', 'geometryType', 'spatialReference', 'fields', 'features', 'exceededTransferLimit']\n",
      "ğŸ“Š Features neste arquivo: 1000\n",
      "ğŸ·ï¸ Campos disponÃ­veis: ['POT_MW', 'ALT_TOTAL', 'ALT_TORRE', 'DIAM_ROTOR', 'DATA_ATUALIZACAO', 'EOL_VERSAO_ID', 'NOME_EOL', 'DEN_AEG']...\n",
      "ğŸ“… DATA_ATUALIZACAO exemplo: 1666625847000\n",
      "2025-06-01 17:51:23 - __main__ - INFO - ValidaÃ§Ã£o dos dados extraÃ­dos concluÃ­da com sucesso\n"
     ]
    }
   ],
   "source": [
    "# ValidaÃ§Ã£o dos dados extraÃ­dos\n",
    "if 'saved_files' in locals() and saved_files:\n",
    "    print(\"ğŸ” VALIDANDO DADOS EXTRAÃDOS...\")\n",
    "    \n",
    "    try:\n",
    "        # ValidaÃ§Ã£o usando funÃ§Ã£o do mÃ³dulo validators\n",
    "        validation_ok = validate_extraction_results(\n",
    "            saved_files=saved_files,\n",
    "            expected_records=0  # A funÃ§Ã£o vai descobrir automaticamente\n",
    "        )\n",
    "        \n",
    "        if validation_ok:\n",
    "            print(\"âœ… ValidaÃ§Ã£o dos dados extraÃ­dos concluÃ­da!\")\n",
    "        else:\n",
    "            print(\"âŒ Falha na validaÃ§Ã£o dos dados extraÃ­dos\")\n",
    "            \n",
    "        # Explorar estrutura de um arquivo como exemplo\n",
    "        print(\"\\nğŸ” EXPLORANDO ESTRUTURA DOS DADOS:\")\n",
    "        first_file = saved_files[0]\n",
    "        print(f\"ğŸ“ Arquivo exemplo: {Path(first_file).name}\")\n",
    "        \n",
    "        with open(first_file, 'r', encoding='utf-8') as f:\n",
    "            sample_data = json.load(f)\n",
    "        \n",
    "        print(f\"ğŸ“‹ Chaves principais: {list(sample_data.keys())}\")\n",
    "        \n",
    "        if 'features' in sample_data:\n",
    "            features = sample_data['features']\n",
    "            print(f\"ğŸ“Š Features neste arquivo: {len(features)}\")\n",
    "            \n",
    "            if features:\n",
    "                first_feature = features[0]\n",
    "                attrs = first_feature.get('attributes', {})\n",
    "                print(f\"ğŸ·ï¸ Campos disponÃ­veis: {list(attrs.keys())[:8]}...\")  # Primeiros 8\n",
    "                \n",
    "                # Mostrar campo de data de atualizaÃ§Ã£o\n",
    "                if 'DATA_ATUALIZACAO' in attrs:\n",
    "                    data_atualizacao = attrs['DATA_ATUALIZACAO']\n",
    "                    print(f\"ğŸ“… DATA_ATUALIZACAO exemplo: {data_atualizacao}\")\n",
    "        \n",
    "        logger.info(\"ValidaÃ§Ã£o dos dados extraÃ­dos concluÃ­da com sucesso\")\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"âŒ Erro durante validaÃ§Ã£o: {e}\")\n",
    "        logger.error(f\"Erro durante validaÃ§Ã£o: {e}\")\n",
    "else:\n",
    "    print(\"âš ï¸ Nenhum arquivo para validar. A extraÃ§Ã£o pode ter sido pulada (idempotÃªncia).\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## ğŸ”„ 4. Pipeline de TransformaÃ§Ã£o - JSON â†’ Parquet\n",
    "\n",
    "Transforma os arquivos JSON em Parquet otimizado com dados geogrÃ¡ficos processados (lat/long extraÃ­dos)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ğŸ”„ VERIFICANDO NECESSIDADE DE TRANSFORMAÃ‡ÃƒO...\n",
      "==================================================\n",
      "2025-06-01 17:51:23 - transformation.processors - INFO - Descobertos 24 arquivos JSON para processar\n",
      "ğŸ“Š STATUS DA TRANSFORMAÃ‡ÃƒO:\n",
      "  ğŸ”„ Precisa transformar: True\n",
      "  ğŸ“ Motivo: TransformaÃ§Ã£o necessÃ¡ria\n",
      "  ğŸ—‚ï¸ Arquivos JSON encontrados: 24\n",
      "  ğŸ“¦ Arquivos Parquet existentes: 0\n",
      "\n",
      "==================================================\n"
     ]
    }
   ],
   "source": [
    "# Instanciar processador e verificar necessidade de transformaÃ§Ã£o\n",
    "print(\"ğŸ”„ VERIFICANDO NECESSIDADE DE TRANSFORMAÃ‡ÃƒO...\")\n",
    "print(\"=\"*50)\n",
    "\n",
    "processor = DataProcessor()\n",
    "transform_check = processor.check_transformation_needed()\n",
    "\n",
    "print(f\"ğŸ“Š STATUS DA TRANSFORMAÃ‡ÃƒO:\")\n",
    "print(f\"  ğŸ”„ Precisa transformar: {transform_check['needs_transformation']}\")\n",
    "print(f\"  ğŸ“ Motivo: {transform_check['reason']}\")\n",
    "\n",
    "if 'json_count' in transform_check:\n",
    "    print(f\"  ğŸ—‚ï¸ Arquivos JSON encontrados: {transform_check['json_count']}\")\n",
    "if 'parquet_count' in transform_check:\n",
    "    print(f\"  ğŸ“¦ Arquivos Parquet existentes: {transform_check['parquet_count']}\")\n",
    "\n",
    "print(\"\\n\" + \"=\"*50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ğŸ”„ EXECUTANDO TRANSFORMAÃ‡ÃƒO JSON â†’ PARQUET...\n",
      "(Sistema converte JSON para Parquet com coordenadas lat/long extraÃ­das)\n",
      "\n",
      "2025-06-01 17:51:23 - transformation.processors - INFO - Descobertos 24 arquivos JSON para processar\n",
      "2025-06-01 17:51:23 - transformation.processors - INFO - ğŸ”„ TransformaÃ§Ã£o necessÃ¡ria: {'needs_transformation': True, 'reason': 'TransformaÃ§Ã£o necessÃ¡ria', 'json_count': 24, 'parquet_count': 0}\n",
      "2025-06-01 17:51:23 - transformation.processors - INFO - Descobertos 24 arquivos JSON para processar\n",
      "2025-06-01 17:51:23 - transformation.processors - INFO - Iniciando processamento de 24 arquivos...\n",
      "2025-06-01 17:51:23 - transformation.processors - INFO - Processado aerogeradores_raw_20250601_175037_page_0003.json: 1000 registros\n",
      "2025-06-01 17:51:23 - transformation.processors - INFO - Processado aerogeradores_raw_20250601_175037_page_0001.json: 1000 registros\n",
      "2025-06-01 17:51:23 - transformation.geo_utils - INFO - ValidaÃ§Ã£o geogrÃ¡fica: 1000/1000 registros vÃ¡lidos\n",
      "2025-06-01 17:51:23 - transformation.processors - INFO - Processado aerogeradores_raw_20250601_175037_page_0002.json: 1000 registros\n",
      "2025-06-01 17:51:23 - transformation.processors - INFO - Processado aerogeradores_raw_20250601_175037_page_0004.json: 1000 registros\n",
      "2025-06-01 17:51:23 - transformation.geo_utils - INFO - ValidaÃ§Ã£o geogrÃ¡fica: 1000/1000 registros vÃ¡lidos\n",
      "2025-06-01 17:51:23 - transformation.geo_utils - INFO - ValidaÃ§Ã£o geogrÃ¡fica: 1000/1000 registros vÃ¡lidos\n",
      "2025-06-01 17:51:23 - transformation.geo_utils - INFO - ValidaÃ§Ã£o geogrÃ¡fica: 1000/1000 registros vÃ¡lidos\n",
      "2025-06-01 17:51:23 - transformation.processors - INFO - Salvo aerogeradores_processed_20250601_175037_page_0002.parquet: 1000 registros, 0.09 MB\n",
      "2025-06-01 17:51:23 - transformation.processors - INFO - Salvo aerogeradores_processed_20250601_175037_page_0001.parquet: 1000 registros, 0.09 MB\n",
      "2025-06-01 17:51:23 - transformation.processors - INFO - Salvo aerogeradores_processed_20250601_175037_page_0003.parquet: 1000 registros, 0.10 MB\n",
      "2025-06-01 17:51:23 - transformation.processors - INFO - Salvo aerogeradores_processed_20250601_175037_page_0004.parquet: 1000 registros, 0.10 MB\n",
      "2025-06-01 17:51:23 - transformation.processors - INFO - âœ… Processado: aerogeradores_raw_20250601_175037_page_0002.json\n",
      "2025-06-01 17:51:23 - transformation.processors - INFO - âœ… Processado: aerogeradores_raw_20250601_175037_page_0001.json\n",
      "2025-06-01 17:51:23 - transformation.processors - INFO - âœ… Processado: aerogeradores_raw_20250601_175037_page_0003.json\n",
      "2025-06-01 17:51:23 - transformation.processors - INFO - âœ… Processado: aerogeradores_raw_20250601_175037_page_0004.json\n",
      "2025-06-01 17:51:23 - transformation.processors - INFO - Processado aerogeradores_raw_20250601_175037_page_0005.json: 1000 registros\n",
      "2025-06-01 17:51:23 - transformation.geo_utils - INFO - ValidaÃ§Ã£o geogrÃ¡fica: 1000/1000 registros vÃ¡lidos\n",
      "2025-06-01 17:51:23 - transformation.processors - INFO - Processado aerogeradores_raw_20250601_175037_page_0006.json: 1000 registros\n",
      "2025-06-01 17:51:23 - transformation.processors - INFO - Processado aerogeradores_raw_20250601_175037_page_0007.json: 1000 registros\n",
      "2025-06-01 17:51:23 - transformation.geo_utils - INFO - ValidaÃ§Ã£o geogrÃ¡fica: 1000/1000 registros vÃ¡lidos\n",
      "2025-06-01 17:51:23 - transformation.processors - INFO - Processado aerogeradores_raw_20250601_175037_page_0008.json: 1000 registros\n",
      "2025-06-01 17:51:23 - transformation.geo_utils - INFO - ValidaÃ§Ã£o geogrÃ¡fica: 1000/1000 registros vÃ¡lidos\n",
      "2025-06-01 17:51:23 - transformation.geo_utils - INFO - ValidaÃ§Ã£o geogrÃ¡fica: 1000/1000 registros vÃ¡lidos\n",
      "2025-06-01 17:51:23 - transformation.processors - INFO - Salvo aerogeradores_processed_20250601_175037_page_0007.parquet: 1000 registros, 0.10 MB\n",
      "2025-06-01 17:51:23 - transformation.processors - INFO - Salvo aerogeradores_processed_20250601_175037_page_0006.parquet: 1000 registros, 0.10 MB\n",
      "2025-06-01 17:51:23 - transformation.processors - INFO - âœ… Processado: aerogeradores_raw_20250601_175037_page_0007.json\n",
      "2025-06-01 17:51:23 - transformation.processors - INFO - Salvo aerogeradores_processed_20250601_175037_page_0008.parquet: 1000 registros, 0.10 MB\n",
      "2025-06-01 17:51:23 - transformation.processors - INFO - Salvo aerogeradores_processed_20250601_175037_page_0005.parquet: 1000 registros, 0.10 MB\n",
      "2025-06-01 17:51:23 - transformation.processors - INFO - âœ… Processado: aerogeradores_raw_20250601_175037_page_0006.json\n",
      "2025-06-01 17:51:23 - transformation.processors - INFO - Processado aerogeradores_raw_20250601_175037_page_0010.json: 1000 registros\n",
      "2025-06-01 17:51:23 - transformation.processors - INFO - Processado aerogeradores_raw_20250601_175037_page_0009.json: 1000 registros\n",
      "2025-06-01 17:51:23 - transformation.geo_utils - INFO - ValidaÃ§Ã£o geogrÃ¡fica: 1000/1000 registros vÃ¡lidos\n",
      "2025-06-01 17:51:23 - transformation.processors - INFO - âœ… Processado: aerogeradores_raw_20250601_175037_page_0008.json\n",
      "2025-06-01 17:51:23 - transformation.geo_utils - INFO - ValidaÃ§Ã£o geogrÃ¡fica: 1000/1000 registros vÃ¡lidos\n",
      "2025-06-01 17:51:23 - transformation.processors - INFO - âœ… Processado: aerogeradores_raw_20250601_175037_page_0005.json\n",
      "2025-06-01 17:51:23 - transformation.processors - INFO - Processado aerogeradores_raw_20250601_175037_page_0012.json: 1000 registros\n",
      "2025-06-01 17:51:23 - transformation.geo_utils - INFO - ValidaÃ§Ã£o geogrÃ¡fica: 1000/1000 registros vÃ¡lidos\n",
      "2025-06-01 17:51:23 - transformation.processors - INFO - Processado aerogeradores_raw_20250601_175037_page_0011.json: 1000 registros\n",
      "2025-06-01 17:51:23 - transformation.geo_utils - INFO - ValidaÃ§Ã£o geogrÃ¡fica: 1000/1000 registros vÃ¡lidos\n",
      "2025-06-01 17:51:23 - transformation.processors - INFO - Salvo aerogeradores_processed_20250601_175037_page_0009.parquet: 1000 registros, 0.09 MB\n",
      "2025-06-01 17:51:23 - transformation.processors - INFO - âœ… Processado: aerogeradores_raw_20250601_175037_page_0009.json\n",
      "2025-06-01 17:51:23 - transformation.processors - INFO - Salvo aerogeradores_processed_20250601_175037_page_0010.parquet: 1000 registros, 0.07 MB\n",
      "2025-06-01 17:51:23 - transformation.processors - INFO - âœ… Processado: aerogeradores_raw_20250601_175037_page_0010.json\n",
      "2025-06-01 17:51:23 - transformation.processors - INFO - Salvo aerogeradores_processed_20250601_175037_page_0012.parquet: 1000 registros, 0.07 MB\n",
      "2025-06-01 17:51:23 - transformation.processors - INFO - âœ… Processado: aerogeradores_raw_20250601_175037_page_0012.json\n",
      "2025-06-01 17:51:23 - transformation.processors - INFO - Processado aerogeradores_raw_20250601_175037_page_0013.json: 1000 registros\n",
      "2025-06-01 17:51:23 - transformation.geo_utils - INFO - ValidaÃ§Ã£o geogrÃ¡fica: 1000/1000 registros vÃ¡lidos\n",
      "2025-06-01 17:51:23 - transformation.processors - INFO - Processado aerogeradores_raw_20250601_175037_page_0014.json: 1000 registros\n",
      "2025-06-01 17:51:23 - transformation.geo_utils - INFO - ValidaÃ§Ã£o geogrÃ¡fica: 1000/1000 registros vÃ¡lidos\n",
      "2025-06-01 17:51:23 - transformation.processors - INFO - Salvo aerogeradores_processed_20250601_175037_page_0011.parquet: 1000 registros, 0.07 MB\n",
      "2025-06-01 17:51:23 - transformation.processors - INFO - Processado aerogeradores_raw_20250601_175037_page_0015.json: 1000 registros\n",
      "2025-06-01 17:51:23 - transformation.processors - INFO - âœ… Processado: aerogeradores_raw_20250601_175037_page_0011.json\n",
      "2025-06-01 17:51:23 - transformation.geo_utils - INFO - ValidaÃ§Ã£o geogrÃ¡fica: 1000/1000 registros vÃ¡lidos\n",
      "2025-06-01 17:51:23 - transformation.processors - INFO - Salvo aerogeradores_processed_20250601_175037_page_0014.parquet: 1000 registros, 0.07 MB\n",
      "2025-06-01 17:51:23 - transformation.processors - INFO - âœ… Processado: aerogeradores_raw_20250601_175037_page_0014.json\n",
      "2025-06-01 17:51:23 - transformation.processors - INFO - Salvo aerogeradores_processed_20250601_175037_page_0013.parquet: 1000 registros, 0.07 MB\n",
      "2025-06-01 17:51:23 - transformation.processors - INFO - âœ… Processado: aerogeradores_raw_20250601_175037_page_0013.json\n",
      "2025-06-01 17:51:23 - transformation.processors - INFO - Processado aerogeradores_raw_20250601_175037_page_0016.json: 1000 registros\n",
      "2025-06-01 17:51:23 - transformation.geo_utils - INFO - ValidaÃ§Ã£o geogrÃ¡fica: 1000/1000 registros vÃ¡lidos\n",
      "2025-06-01 17:51:23 - transformation.processors - INFO - Processado aerogeradores_raw_20250601_175037_page_0017.json: 1000 registros\n",
      "2025-06-01 17:51:23 - transformation.processors - INFO - Processado aerogeradores_raw_20250601_175037_page_0018.json: 1000 registros\n",
      "2025-06-01 17:51:23 - transformation.geo_utils - INFO - ValidaÃ§Ã£o geogrÃ¡fica: 1000/1000 registros vÃ¡lidos\n",
      "2025-06-01 17:51:23 - transformation.processors - INFO - Salvo aerogeradores_processed_20250601_175037_page_0015.parquet: 1000 registros, 0.08 MB\n",
      "2025-06-01 17:51:23 - transformation.geo_utils - INFO - ValidaÃ§Ã£o geogrÃ¡fica: 1000/1000 registros vÃ¡lidos\n",
      "2025-06-01 17:51:23 - transformation.processors - INFO - âœ… Processado: aerogeradores_raw_20250601_175037_page_0015.json\n",
      "2025-06-01 17:51:23 - transformation.processors - INFO - Salvo aerogeradores_processed_20250601_175037_page_0016.parquet: 1000 registros, 0.07 MB\n",
      "2025-06-01 17:51:23 - transformation.processors - INFO - âœ… Processado: aerogeradores_raw_20250601_175037_page_0016.json\n",
      "2025-06-01 17:51:23 - transformation.processors - INFO - Processado aerogeradores_raw_20250601_175037_page_0019.json: 1000 registros\n",
      "2025-06-01 17:51:23 - transformation.geo_utils - INFO - ValidaÃ§Ã£o geogrÃ¡fica: 1000/1000 registros vÃ¡lidos\n",
      "2025-06-01 17:51:23 - transformation.processors - INFO - Salvo aerogeradores_processed_20250601_175037_page_0018.parquet: 1000 registros, 0.07 MB\n",
      "2025-06-01 17:51:23 - transformation.processors - INFO - Processado aerogeradores_raw_20250601_175037_page_0020.json: 1000 registros\n",
      "2025-06-01 17:51:23 - transformation.processors - INFO - âœ… Processado: aerogeradores_raw_20250601_175037_page_0018.json\n",
      "2025-06-01 17:51:23 - transformation.geo_utils - INFO - ValidaÃ§Ã£o geogrÃ¡fica: 1000/1000 registros vÃ¡lidos\n",
      "2025-06-01 17:51:23 - transformation.processors - INFO - Salvo aerogeradores_processed_20250601_175037_page_0017.parquet: 1000 registros, 0.07 MB\n",
      "2025-06-01 17:51:23 - transformation.processors - INFO - âœ… Processado: aerogeradores_raw_20250601_175037_page_0017.json\n",
      "2025-06-01 17:51:23 - transformation.processors - INFO - Salvo aerogeradores_processed_20250601_175037_page_0019.parquet: 1000 registros, 0.07 MB\n",
      "2025-06-01 17:51:23 - transformation.processors - INFO - Processado aerogeradores_raw_20250601_175037_page_0021.json: 1000 registros\n",
      "2025-06-01 17:51:23 - transformation.processors - INFO - âœ… Processado: aerogeradores_raw_20250601_175037_page_0019.json\n",
      "2025-06-01 17:51:23 - transformation.geo_utils - INFO - ValidaÃ§Ã£o geogrÃ¡fica: 1000/1000 registros vÃ¡lidos\n",
      "2025-06-01 17:51:23 - transformation.processors - INFO - Processado aerogeradores_raw_20250601_175037_page_0022.json: 1000 registros\n",
      "2025-06-01 17:51:23 - transformation.geo_utils - INFO - ValidaÃ§Ã£o geogrÃ¡fica: 1000/1000 registros vÃ¡lidos\n",
      "2025-06-01 17:51:23 - transformation.processors - INFO - Processado aerogeradores_raw_20250601_175037_page_0023.json: 1000 registros\n",
      "2025-06-01 17:51:23 - transformation.geo_utils - INFO - ValidaÃ§Ã£o geogrÃ¡fica: 1000/1000 registros vÃ¡lidos\n",
      "2025-06-01 17:51:23 - transformation.processors - INFO - Salvo aerogeradores_processed_20250601_175037_page_0020.parquet: 1000 registros, 0.07 MB\n",
      "2025-06-01 17:51:23 - transformation.processors - INFO - âœ… Processado: aerogeradores_raw_20250601_175037_page_0020.json\n",
      "2025-06-01 17:51:23 - transformation.processors - INFO - Processado aerogeradores_raw_20250601_175037_page_0024.json: 522 registros\n",
      "2025-06-01 17:51:23 - transformation.geo_utils - INFO - ValidaÃ§Ã£o geogrÃ¡fica: 522/522 registros vÃ¡lidos\n",
      "2025-06-01 17:51:23 - transformation.processors - INFO - Salvo aerogeradores_processed_20250601_175037_page_0022.parquet: 1000 registros, 0.07 MB\n",
      "2025-06-01 17:51:23 - transformation.processors - INFO - âœ… Processado: aerogeradores_raw_20250601_175037_page_0022.json\n",
      "2025-06-01 17:51:23 - transformation.processors - INFO - Salvo aerogeradores_processed_20250601_175037_page_0021.parquet: 1000 registros, 0.07 MB\n",
      "2025-06-01 17:51:23 - transformation.processors - INFO - Salvo aerogeradores_processed_20250601_175037_page_0023.parquet: 1000 registros, 0.07 MB\n",
      "2025-06-01 17:51:23 - transformation.processors - INFO - âœ… Processado: aerogeradores_raw_20250601_175037_page_0021.json\n",
      "2025-06-01 17:51:23 - transformation.processors - INFO - âœ… Processado: aerogeradores_raw_20250601_175037_page_0023.json\n",
      "2025-06-01 17:51:23 - transformation.processors - INFO - Salvo aerogeradores_processed_20250601_175037_page_0024.parquet: 522 registros, 0.05 MB\n",
      "2025-06-01 17:51:23 - transformation.processors - INFO - âœ… Processado: aerogeradores_raw_20250601_175037_page_0024.json\n",
      "2025-06-01 17:51:23 - transformation.processors - INFO - Processamento concluÃ­do!\n",
      "2025-06-01 17:51:23 - transformation.processors - INFO - Arquivos processados: 24\n",
      "2025-06-01 17:51:23 - transformation.processors - INFO - Arquivos com falha: 0\n",
      "\n",
      "ğŸ“Š RESULTADO DA TRANSFORMAÃ‡ÃƒO:\n",
      "âœ… Arquivos Parquet criados: 24\n",
      "\n",
      "ğŸ“‹ Arquivos Parquet (primeiros 3):\n",
      "  1. aerogeradores_processed_20250601_175037_page_0002.parquet (97.1 KB, 1,000 registros)\n",
      "  2. aerogeradores_processed_20250601_175037_page_0001.parquet (95.1 KB, 1,000 registros)\n",
      "  3. aerogeradores_processed_20250601_175037_page_0003.parquet (100.3 KB, 1,000 registros)\n",
      "  ... e mais 21 arquivos\n",
      "\n",
      "ğŸ’¾ Tamanho total: 1.95 MB\n",
      "ğŸ“Š Total de registros: 23,522\n",
      "ğŸ“ LocalizaÃ§Ã£o: data/processed/\n",
      "ğŸ—œï¸ CompressÃ£o: 11.5% do tamanho original JSON\n",
      "2025-06-01 17:51:23 - __main__ - INFO - TransformaÃ§Ã£o concluÃ­da: 24 parquets\n"
     ]
    }
   ],
   "source": [
    "# Executar transformaÃ§Ã£o (idempotente - sÃ³ processa se necessÃ¡rio)\n",
    "print(\"ğŸ”„ EXECUTANDO TRANSFORMAÃ‡ÃƒO JSON â†’ PARQUET...\")\n",
    "print(\"(Sistema converte JSON para Parquet com coordenadas lat/long extraÃ­das)\\n\")\n",
    "\n",
    "try:\n",
    "    # TransformaÃ§Ã£o idempotente (force_refresh=False por padrÃ£o)\n",
    "    processed_files = processor.process_all_files()\n",
    "    \n",
    "    print(f\"\\nğŸ“Š RESULTADO DA TRANSFORMAÃ‡ÃƒO:\")\n",
    "    print(f\"âœ… Arquivos Parquet criados: {len(processed_files)}\")\n",
    "    \n",
    "    if processed_files:\n",
    "        # Calcular estatÃ­sticas dos parquets\n",
    "        total_size = 0\n",
    "        total_records = 0\n",
    "        \n",
    "        print(f\"\\nğŸ“‹ Arquivos Parquet (primeiros 3):\")\n",
    "        for i, file_path in enumerate(processed_files[:3]):\n",
    "            filename = Path(file_path).name\n",
    "            size = Path(file_path).stat().st_size / 1024  # KB\n",
    "            total_size += Path(file_path).stat().st_size\n",
    "            \n",
    "            # Contar registros no parquet\n",
    "            try:\n",
    "                df = pd.read_parquet(file_path)\n",
    "                records = len(df)\n",
    "                total_records += records\n",
    "                print(f\"  {i+1}. {filename} ({size:.1f} KB, {records:,} registros)\")\n",
    "            except:\n",
    "                print(f\"  {i+1}. {filename} ({size:.1f} KB)\")\n",
    "        \n",
    "        if len(processed_files) > 3:\n",
    "            print(f\"  ... e mais {len(processed_files) - 3} arquivos\")\n",
    "            \n",
    "            # Contar registros restantes\n",
    "            for file_path in processed_files[3:]:\n",
    "                total_size += Path(file_path).stat().st_size\n",
    "                try:\n",
    "                    df = pd.read_parquet(file_path)\n",
    "                    total_records += len(df)\n",
    "                except:\n",
    "                    pass\n",
    "        \n",
    "        print(f\"\\nğŸ’¾ Tamanho total: {total_size / 1024 / 1024:.2f} MB\")\n",
    "        print(f\"ğŸ“Š Total de registros: {total_records:,}\")\n",
    "        print(f\"ğŸ“ LocalizaÃ§Ã£o: data/processed/\")\n",
    "        print(f\"ğŸ—œï¸ CompressÃ£o: {((total_size / 1024 / 1024) / 17) * 100:.1f}% do tamanho original JSON\")\n",
    "    \n",
    "    logger.info(f\"TransformaÃ§Ã£o concluÃ­da: {len(processed_files)} parquets\")\n",
    "    \n",
    "except Exception as e:\n",
    "    print(f\"âŒ Erro durante transformaÃ§Ã£o: {e}\")\n",
    "    logger.error(f\"Erro durante transformaÃ§Ã£o: {e}\")\n",
    "    raise"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## ğŸ“Š 5. Pipeline de ConsolidaÃ§Ã£o - Parquet â†’ CSV Final\n",
    "\n",
    "Consolida todos os Parquets em um Ãºnico CSV otimizado para o Tableau, com validaÃ§Ãµes inteligentes de conteÃºdo."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ğŸ“Š VERIFICANDO NECESSIDADE DE CONSOLIDAÃ‡ÃƒO...\n",
      "==================================================\n",
      "2025-06-01 17:51:23 - consolidation.consolidators - INFO - Descobertos 24 arquivos Parquet para consolidar\n",
      "ğŸ“Š STATUS DA CONSOLIDAÃ‡ÃƒO:\n",
      "  ğŸ”„ Precisa consolidar: True\n",
      "  ğŸ“ Motivo: Nenhum CSV encontrado\n",
      "  ğŸ“¦ Arquivos Parquet encontrados: 24\n",
      "\n",
      "==================================================\n"
     ]
    }
   ],
   "source": [
    "# Instanciar consolidador e verificar necessidade de consolidaÃ§Ã£o\n",
    "print(\"ğŸ“Š VERIFICANDO NECESSIDADE DE CONSOLIDAÃ‡ÃƒO...\")\n",
    "print(\"=\"*50)\n",
    "\n",
    "consolidator = DataConsolidator()\n",
    "consolidation_check = consolidator.check_consolidation_needed()\n",
    "\n",
    "print(f\"ğŸ“Š STATUS DA CONSOLIDAÃ‡ÃƒO:\")\n",
    "print(f\"  ğŸ”„ Precisa consolidar: {consolidation_check['needs_consolidation']}\")\n",
    "print(f\"  ğŸ“ Motivo: {consolidation_check['reason']}\")\n",
    "\n",
    "if 'csv_records' in consolidation_check:\n",
    "    print(f\"  ğŸ“„ Registros no CSV atual: {consolidation_check['csv_records']:,}\")\n",
    "if 'expected_records' in consolidation_check:\n",
    "    print(f\"  ğŸ“¦ Registros esperados: {consolidation_check['expected_records']:,}\")\n",
    "if 'parquet_count' in consolidation_check:\n",
    "    print(f\"  ğŸ“¦ Arquivos Parquet encontrados: {consolidation_check['parquet_count']}\")\n",
    "\n",
    "print(\"\\n\" + \"=\"*50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ğŸ“Š EXECUTANDO CONSOLIDAÃ‡ÃƒO PARQUET â†’ CSV...\n",
      "(Sistema cria CSV final otimizado para Tableau com dados limpos e validados)\n",
      "\n",
      "2025-06-01 17:51:23 - consolidation.consolidators - INFO - Descobertos 24 arquivos Parquet para consolidar\n",
      "2025-06-01 17:51:23 - consolidation.consolidators - INFO - ğŸ”„ ConsolidaÃ§Ã£o necessÃ¡ria: Nenhum CSV encontrado\n",
      "2025-06-01 17:51:23 - consolidation.consolidators - INFO - Iniciando consolidaÃ§Ã£o completa...\n",
      "2025-06-01 17:51:23 - consolidation.consolidators - INFO - Descobertos 24 arquivos Parquet para consolidar\n",
      "2025-06-01 17:51:23 - consolidation.consolidators - INFO - Carregando 24 arquivos Parquet...\n",
      "2025-06-01 17:51:23 - consolidation.consolidators - INFO - Consolidando 24 DataFrames...\n",
      "2025-06-01 17:51:23 - consolidation.consolidators - INFO - ConsolidaÃ§Ã£o concluÃ­da: 23522 registros totais\n",
      "2025-06-01 17:51:23 - consolidation.consolidators - INFO - Otimizando dados para Tableau...\n",
      "2025-06-01 17:51:23 - consolidation.consolidators - INFO - Removidas colunas: ['geometry_wkt']\n",
      "2025-06-01 17:51:23 - consolidation.consolidators - INFO - Valores nulos encontrados: {'ALT_TORRE': 4, 'EOL_VERSAO_ID': 9, 'OPERACAO': 206, 'PROPRIETARIO': 9, 'ORIGEM': 23522, 'UF': 9, 'CEG': 9}\n",
      "2025-06-01 17:51:23 - consolidation.consolidators - INFO - Validando dados finais...\n",
      "2025-06-01 17:51:23 - consolidation.consolidators - INFO - ValidaÃ§Ã£o de dados finais concluÃ­da\n",
      "2025-06-01 17:51:23 - consolidation.consolidators - INFO - OtimizaÃ§Ã£o concluÃ­da: 23522 registros, 21 colunas\n",
      "2025-06-01 17:51:24 - consolidation.consolidators - INFO - CSV salvo: aerogeradores_consolidado_20250601_175123.csv\n",
      "2025-06-01 17:51:24 - consolidation.consolidators - INFO - Registros: 23522\n",
      "2025-06-01 17:51:24 - consolidation.consolidators - INFO - Colunas: 21\n",
      "2025-06-01 17:51:24 - consolidation.consolidators - INFO - Tamanho: 5.89 MB\n",
      "2025-06-01 17:51:24 - consolidation.consolidators - INFO - LocalizaÃ§Ã£o: /home/victor-jose/Documents/projetos/hometown/data/output/aerogeradores_consolidado_20250601_175123.csv\n",
      "2025-06-01 17:51:24 - consolidation.consolidators - INFO - ConsolidaÃ§Ã£o completa concluÃ­da com sucesso!\n",
      "\n",
      "ğŸ“Š RESULTADO DA CONSOLIDAÃ‡ÃƒO:\n",
      "âœ… CSV final criado: aerogeradores_consolidado_20250601_175123.csv\n",
      "ğŸ’¾ Tamanho do arquivo: 5.89 MB\n",
      "ğŸ“ LocalizaÃ§Ã£o completa: /home/victor-jose/Documents/projetos/hometown/data/output/aerogeradores_consolidado_20250601_175123.csv\n",
      "\n",
      "ğŸ” ANÃLISE DO CSV FINAL:\n",
      "ğŸ“Š Total de registros: 23,522\n",
      "ğŸ“‹ Total de colunas: 21\n",
      "ğŸ’¾ Uso de memÃ³ria: 15.81 MB\n",
      "\n",
      "ğŸ—ºï¸ COORDENADAS GEOGRÃFICAS:\n",
      "  ğŸ“ Latitude: -33.741842 â†’ -2.602600\n",
      "  ğŸ“ Longitude: -56.457069 â†’ -34.967495\n",
      "  ğŸ‡§ğŸ‡· Cobertura: Todo o territÃ³rio brasileiro\n",
      "\n",
      "ğŸ“‚ ESTRUTURA DOS DADOS (primeiras 10 colunas):\n",
      "   1. latitude\n",
      "   2. longitude\n",
      "   3. POT_MW\n",
      "   4. ALT_TOTAL\n",
      "   5. ALT_TORRE\n",
      "   6. DIAM_ROTOR\n",
      "   7. DATA_ATUALIZACAO\n",
      "   8. EOL_VERSAO_ID\n",
      "   9. NOME_EOL\n",
      "  10. DEN_AEG\n",
      "  ... e mais 11 colunas\n",
      "\n",
      "ğŸ¯ CSV PRONTO PARA TABLEAU!\n",
      "   â€¢ Coordenadas no inÃ­cio para mapas automÃ¡ticos\n",
      "   â€¢ Dados limpos e validados\n",
      "   â€¢ Formato otimizado para anÃ¡lise\n",
      "2025-06-01 17:51:24 - __main__ - INFO - ConsolidaÃ§Ã£o concluÃ­da: aerogeradores_consolidado_20250601_175123.csv\n"
     ]
    }
   ],
   "source": [
    "# Executar consolidaÃ§Ã£o (idempotente - sÃ³ consolida se necessÃ¡rio)\n",
    "print(\"ğŸ“Š EXECUTANDO CONSOLIDAÃ‡ÃƒO PARQUET â†’ CSV...\")\n",
    "print(\"(Sistema cria CSV final otimizado para Tableau com dados limpos e validados)\\n\")\n",
    "\n",
    "try:\n",
    "    # ConsolidaÃ§Ã£o idempotente (force_refresh=False por padrÃ£o)\n",
    "    output_path = consolidator.consolidate_all()\n",
    "    \n",
    "    print(f\"\\nğŸ“Š RESULTADO DA CONSOLIDAÃ‡ÃƒO:\")\n",
    "    \n",
    "    if output_path and Path(output_path).exists():\n",
    "        filename = Path(output_path).name\n",
    "        file_size = Path(output_path).stat().st_size / 1024 / 1024  # MB\n",
    "        \n",
    "        print(f\"âœ… CSV final criado: {filename}\")\n",
    "        print(f\"ğŸ’¾ Tamanho do arquivo: {file_size:.2f} MB\")\n",
    "        print(f\"ğŸ“ LocalizaÃ§Ã£o completa: {output_path}\")\n",
    "        \n",
    "        # Analisar conteÃºdo do CSV final\n",
    "        print(f\"\\nğŸ” ANÃLISE DO CSV FINAL:\")\n",
    "        df_final = pd.read_csv(output_path)\n",
    "        summary = consolidator.get_data_summary(df_final)\n",
    "        \n",
    "        print(f\"ğŸ“Š Total de registros: {summary['total_records']:,}\")\n",
    "        print(f\"ğŸ“‹ Total de colunas: {summary['total_columns']}\")\n",
    "        print(f\"ğŸ’¾ Uso de memÃ³ria: {summary['memory_usage_mb']:.2f} MB\")\n",
    "        \n",
    "        # Coordenadas geogrÃ¡ficas\n",
    "        if 'coordinate_stats' in summary:\n",
    "            coords = summary['coordinate_stats']\n",
    "            print(f\"\\nğŸ—ºï¸ COORDENADAS GEOGRÃFICAS:\")\n",
    "            print(f\"  ğŸ“ Latitude: {coords['lat_min']:.6f} â†’ {coords['lat_max']:.6f}\")\n",
    "            print(f\"  ğŸ“ Longitude: {coords['lon_min']:.6f} â†’ {coords['lon_max']:.6f}\")\n",
    "            print(f\"  ğŸ‡§ğŸ‡· Cobertura: Todo o territÃ³rio brasileiro\")\n",
    "        \n",
    "        # Estrutura das colunas\n",
    "        print(f\"\\nğŸ“‚ ESTRUTURA DOS DADOS (primeiras 10 colunas):\")\n",
    "        for i, col in enumerate(summary['columns'][:10], 1):\n",
    "            print(f\"  {i:2d}. {col}\")\n",
    "        if len(summary['columns']) > 10:\n",
    "            print(f\"  ... e mais {len(summary['columns']) - 10} colunas\")\n",
    "        \n",
    "        print(f\"\\nğŸ¯ CSV PRONTO PARA TABLEAU!\")\n",
    "        print(f\"   â€¢ Coordenadas no inÃ­cio para mapas automÃ¡ticos\")\n",
    "        print(f\"   â€¢ Dados limpos e validados\")\n",
    "        print(f\"   â€¢ Formato otimizado para anÃ¡lise\")\n",
    "        \n",
    "    else:\n",
    "        print(f\"âš ï¸ Nenhum CSV foi criado (possivelmente devido Ã  idempotÃªncia)\")\n",
    "    \n",
    "    logger.info(f\"ConsolidaÃ§Ã£o concluÃ­da: {filename if output_path else 'pulada'}\")\n",
    "    \n",
    "except Exception as e:\n",
    "    print(f\"âŒ Erro durante consolidaÃ§Ã£o: {e}\")\n",
    "    logger.error(f\"Erro durante consolidaÃ§Ã£o: {e}\")\n",
    "    raise"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "ğŸ”„ TESTE DE FORCE REFRESH\n",
      "========================================\n",
      "âš ï¸ ATENÃ‡ÃƒO: Isso vai reprocessar todos os dados (pode demorar alguns minutos)\n",
      "Descomente as linhas abaixo se quiser testar force refresh:\n",
      "\n",
      "# Force refresh - descomente para executar:\n",
      "# force_files = test_extractor.extract_all_data(force_refresh=True)\n",
      "# force_parquets = test_processor.process_all_files(force_refresh=True)\n",
      "# force_csv = test_consolidator.consolidate_all(force_refresh=True)\n",
      "# print(f'Force refresh: {len(force_files)} JSONs, {len(force_parquets)} Parquets, 1 CSV')\n",
      "\n",
      "ğŸ’¡ O force refresh deve:\n",
      "   â€¢ Limpar dados antigos automaticamente\n",
      "   â€¢ Reprocessar todos os dados do zero\n",
      "   â€¢ Gerar novos timestamps em todos os arquivos\n"
     ]
    }
   ],
   "source": [
    "# Teste de force refresh - deve reprocessar tudo\n",
    "print(\"\\nğŸ”„ TESTE DE FORCE REFRESH\")\n",
    "print(\"=\"*40)\n",
    "print(\"âš ï¸ ATENÃ‡ÃƒO: Isso vai reprocessar todos os dados (pode demorar alguns minutos)\")\n",
    "print(\"Descomente as linhas abaixo se quiser testar force refresh:\\n\")\n",
    "\n",
    "print(\"# Force refresh - descomente para executar:\")\n",
    "print(\"# force_files = test_extractor.extract_all_data(force_refresh=True)\")\n",
    "print(\"# force_parquets = test_processor.process_all_files(force_refresh=True)\")\n",
    "print(\"# force_csv = test_consolidator.consolidate_all(force_refresh=True)\")\n",
    "print(\"# print(f'Force refresh: {len(force_files)} JSONs, {len(force_parquets)} Parquets, 1 CSV')\")\n",
    "\n",
    "print(\"\\nğŸ’¡ O force refresh deve:\")\n",
    "print(\"   â€¢ Limpar dados antigos automaticamente\")\n",
    "print(\"   â€¢ Reprocessar todos os dados do zero\")\n",
    "print(\"   â€¢ Gerar novos timestamps em todos os arquivos\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## ğŸ› ï¸ 7. Comandos de ManutenÃ§Ã£o AvanÃ§ada\n",
    "\n",
    "Ferramentas para limpeza, debug e manutenÃ§Ã£o do pipeline."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ğŸ› ï¸ COMANDOS DE MANUTENÃ‡ÃƒO DISPONÃVEIS\n",
      "==================================================\n",
      "ğŸ“Š STATUS E INFORMAÃ‡Ã•ES:\n",
      "â€¢ show_current_data_status() - Mostra status completo dos dados\n",
      "â€¢ extractor.check_data_freshness() - Verifica se API mudou\n",
      "â€¢ processor.check_transformation_needed() - Verifica necessidade de transformaÃ§Ã£o\n",
      "â€¢ consolidator.check_consolidation_needed() - Verifica necessidade de consolidaÃ§Ã£o\n",
      "\n",
      "ğŸ§¹ LIMPEZA:\n",
      "â€¢ cleanup_all_data() - Remove TODOS os dados (reset completo)\n",
      "â€¢ extractor.cleanup_all_raw_data() - Remove apenas JSONs\n",
      "â€¢ processor.cleanup_all_processed_data() - Remove apenas Parquets\n",
      "â€¢ consolidator.cleanup_all_output_data() - Remove apenas CSVs\n",
      "\n",
      "ğŸ”„ FORCE REFRESH:\n",
      "â€¢ extractor.extract_all_data(force_refresh=True) - ForÃ§a nova extraÃ§Ã£o\n",
      "â€¢ processor.process_all_files(force_refresh=True) - ForÃ§a nova transformaÃ§Ã£o\n",
      "â€¢ consolidator.consolidate_all(force_refresh=True) - ForÃ§a nova consolidaÃ§Ã£o\n",
      "\n",
      "==================================================\n",
      "ğŸ’¡ DICAS:\n",
      "â€¢ Use cleanup_all_data() se quiser recomeÃ§ar do zero\n",
      "â€¢ Use force_refresh=True se suspeitar de dados corrompidos\n",
      "â€¢ O pipeline normal (sem parÃ¢metros) Ã© idempotente e eficiente\n",
      "==================================================\n"
     ]
    }
   ],
   "source": [
    "# Comandos de limpeza e manutenÃ§Ã£o\n",
    "print(\"ğŸ› ï¸ COMANDOS DE MANUTENÃ‡ÃƒO DISPONÃVEIS\")\n",
    "print(\"=\"*50)\n",
    "\n",
    "print(\"ğŸ“Š STATUS E INFORMAÃ‡Ã•ES:\")\n",
    "print(\"â€¢ show_current_data_status() - Mostra status completo dos dados\")\n",
    "print(\"â€¢ extractor.check_data_freshness() - Verifica se API mudou\")\n",
    "print(\"â€¢ processor.check_transformation_needed() - Verifica necessidade de transformaÃ§Ã£o\")\n",
    "print(\"â€¢ consolidator.check_consolidation_needed() - Verifica necessidade de consolidaÃ§Ã£o\")\n",
    "\n",
    "print(\"\\nğŸ§¹ LIMPEZA:\")\n",
    "print(\"â€¢ cleanup_all_data() - Remove TODOS os dados (reset completo)\")\n",
    "print(\"â€¢ extractor.cleanup_all_raw_data() - Remove apenas JSONs\")\n",
    "print(\"â€¢ processor.cleanup_all_processed_data() - Remove apenas Parquets\")\n",
    "print(\"â€¢ consolidator.cleanup_all_output_data() - Remove apenas CSVs\")\n",
    "\n",
    "print(\"\\nğŸ”„ FORCE REFRESH:\")\n",
    "print(\"â€¢ extractor.extract_all_data(force_refresh=True) - ForÃ§a nova extraÃ§Ã£o\")\n",
    "print(\"â€¢ processor.process_all_files(force_refresh=True) - ForÃ§a nova transformaÃ§Ã£o\")\n",
    "print(\"â€¢ consolidator.consolidate_all(force_refresh=True) - ForÃ§a nova consolidaÃ§Ã£o\")\n",
    "\n",
    "print(\"\\n\" + \"=\"*50)\n",
    "print(\"ğŸ’¡ DICAS:\")\n",
    "print(\"â€¢ Use cleanup_all_data() se quiser recomeÃ§ar do zero\")\n",
    "print(\"â€¢ Use force_refresh=True se suspeitar de dados corrompidos\")\n",
    "print(\"â€¢ O pipeline normal (sem parÃ¢metros) Ã© idempotente e eficiente\")\n",
    "print(\"=\"*50)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
